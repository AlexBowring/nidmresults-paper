{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform a simple meta-analysis (as the third level of a hierarchical GLM)\n",
    "based on a set of NIDM-Results exports.\n",
    "\n",
    "@author: Camille Maumet <c.m.j.maumet@warwick.ac.uk>\n",
    "@copyright: University of Warwick 2015\n",
    "\"\"\"\n",
    "import os\n",
    "from rdflib.graph import Graph\n",
    "from rdflib.term import URIRef\n",
    "from subprocess import check_call\n",
    "from nidmresults.objects.constants import SCR_FSL, SCR_SPM\n",
    "import collections\n",
    "import glob\n",
    "import zipfile\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))\n",
    "    data_dir = os.path.join(SCRIPT_DIR, \"input\", \"data\", \"pain\")\n",
    "    print data_dir\n",
    "    assert os.path.isdir(data_dir)\n",
    "\n",
    "    FSL_DESIGN_DIR = os.path.join(\n",
    "        SCRIPT_DIR, \"input\", \"IBMA\", \"fsl_design\")\n",
    "    assert os.path.isdir(FSL_DESIGN_DIR)\n",
    "\n",
    "    out_dir = os.path.join(SCRIPT_DIR, \"output\", \"IBMA\", \"data\")\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    studies = glob.glob(os.path.join(data_dir, '*.nidm.zip'))\n",
    "\n",
    "    con_maps = dict()\n",
    "    varcon_maps = dict()\n",
    "    mask_maps = dict()\n",
    "\n",
    "    ma_mask_name = os.path.join(out_dir, \"mask_ma\")\n",
    "    ma_mask = None\n",
    "\n",
    "    # studies = studies[0:3]\n",
    "\n",
    "    for nidm_file in studies:\n",
    "        study = os.path.basename(nidm_file.replace(\".nidm.zip\", \"\"))\n",
    "        nidm_dir = os.path.join(out_dir, \"pre\", study)\n",
    "        print \"\\nStudy: \" + study\n",
    "\n",
    "        with zipfile.ZipFile(nidm_file) as z:\n",
    "            if not os.path.exists(nidm_dir):\n",
    "                os.makedirs(nidm_dir)\n",
    "            z.extractall(nidm_dir)\n",
    "\n",
    "        nidm_doc = os.path.join(nidm_dir, \"nidm.ttl\")\n",
    "        assert os.path.isfile(nidm_doc)\n",
    "\n",
    "        nidm_graph = Graph()\n",
    "        nidm_graph.parse(nidm_doc, format='turtle')\n",
    "\n",
    "        query = \"\"\"\n",
    "        prefix prov: <http://www.w3.org/ns/prov#>\n",
    "        prefix nidm: <http://purl.org/nidash/nidm#>\n",
    "\n",
    "        prefix contrast_estimation: <http://purl.org/nidash/nidm#NIDM_0000001>\n",
    "        prefix contrast_map: <http://purl.org/nidash/nidm#NIDM_0000002>\n",
    "        prefix stderr_map: <http://purl.org/nidash/nidm#NIDM_0000013>\n",
    "        prefix contrast_name: <http://purl.org/nidash/nidm#NIDM_0000085>\n",
    "        prefix statistic_map: <http://purl.org/nidash/nidm#NIDM_0000076>\n",
    "        prefix mask_map: <http://purl.org/nidash/nidm#NIDM_0000054>\n",
    "\n",
    "        SELECT ?contrastName ?con_file ?std_file\n",
    "        ?mask_file ?software WHERE {\n",
    "         ?con_id a contrast_map: ;\n",
    "              contrast_name: ?contrastName ;\n",
    "              prov:atLocation ?con_file ;\n",
    "              prov:wasGeneratedBy ?con_est .\n",
    "         ?std_id a stderr_map: ;\n",
    "              prov:atLocation ?std_file ;\n",
    "              prov:wasGeneratedBy ?con_est .\n",
    "         ?mask_id a mask_map: ;\n",
    "              prov:atLocation ?mask_file .\n",
    "         ?soft_id a ?software .\n",
    "         ?con_est a contrast_estimation: ;\n",
    "                  prov:wasAssociatedWith ?soft_id ;\n",
    "                  prov:used ?mask_id .\n",
    "\n",
    "          FILTER(?software NOT IN (\n",
    "            prov:SoftwareAgent, prov:Agent))\n",
    "        }\n",
    "\n",
    "        \"\"\"\n",
    "        sd = nidm_graph.query(query)\n",
    "\n",
    "        if sd:\n",
    "            for row in sd:\n",
    "                con_name, con_file, std_file, mask_file, software = row\n",
    "                con_file = os.path.join(nidm_dir, con_file)\n",
    "                std_file = os.path.join(nidm_dir, std_file)\n",
    "                mask_file = os.path.join(nidm_dir, mask_file)\n",
    "\n",
    "                if str(con_name) == \"pain\":\n",
    "                    if software == URIRef(SCR_SPM.uri):\n",
    "                        print \"--> analyzed with SPM\"\n",
    "                        # If study was performed with SPM, reslice to FSL's\n",
    "                        # template space\n",
    "                        for to_reslice in [con_file, std_file, mask_file]:\n",
    "                            file_name = os.path.basename(\n",
    "                                to_reslice).split(\".\")[0]\n",
    "                            resliced_file = os.path.join(\n",
    "                                out_dir, study + \"_\" + file_name + \"_r\")\n",
    "                            cmd = [\n",
    "                                \"cd \\\"\" + nidm_dir + \"\\\";\" +\n",
    "                                \" flirt -in \" + file_name + \" -ref \" +\n",
    "                                \"$FSLDIR/data/standard/MNI152_T1_2mm \" +\n",
    "                                \"-applyxfm -usesqform \" +\n",
    "                                \"-out \" + resliced_file\n",
    "                                ]\n",
    "                            print \"Running \" + \",\".join(cmd)\n",
    "                            check_call(cmd, shell=True)\n",
    "\n",
    "                            if to_reslice == mask_file:\n",
    "                                mask_file = resliced_file\n",
    "                            elif to_reslice == con_file:\n",
    "                                con_maps[study] = resliced_file\n",
    "                            elif to_reslice == std_file:\n",
    "                                std_file = resliced_file\n",
    "\n",
    "                    elif software == URIRef(SCR_FSL.uri):\n",
    "                        print \"--> analyzed with FSL\"\n",
    "                        # If study was performed with FSL, rescale to a target\n",
    "                        # value of 100\n",
    "                        for to_rescale in [con_file, std_file]:\n",
    "                            file_name = os.path.basename(\n",
    "                                to_rescale).split(\".\")[0]\n",
    "                            rescaled_file = os.path.join(\n",
    "                                out_dir, study + \"_\" + file_name + \"_s\")\n",
    "                            cmd = [\n",
    "                                \"cd \\\"\" + nidm_dir + \"\\\";\" +\n",
    "                                \" fslmaths \\\"\" + file_name + \"\\\" -div 100 \" +\n",
    "                                \" \\\"\" + rescaled_file + \"\\\"\"\n",
    "                                ]\n",
    "                            print \"Running \" + \",\".join(cmd)\n",
    "                            check_call(cmd, shell=True)\n",
    "\n",
    "                            if to_rescale == con_file:\n",
    "                                con_maps[study] = \"\\\"\" + rescaled_file + \"\\\"\"\n",
    "                            elif to_rescale == std_file:\n",
    "                                std_file = \"\\\"\" + rescaled_file + \"\\\"\"\n",
    "\n",
    "                        mask_file = mask_file.replace(\"file://.\", nidm_dir)\n",
    "\n",
    "                    else:\n",
    "                        raise Exception(\n",
    "                            'Unknown neuroimaging software: ' + str(software))\n",
    "\n",
    "                    # Create varcope from standard error map\n",
    "                    varcope_file = \"\\\"\" + \\\n",
    "                                   os.path.join(out_dir, study + \"_varcope\") +\\\n",
    "                                   \"\\\"\"\n",
    "                    cmd = [\" fslmaths \" + std_file + \" -sqr \" + varcope_file]\n",
    "                    print \"Running \" + \",\".join(cmd)\n",
    "                    check_call(cmd, shell=True)\n",
    "\n",
    "                    varcon_maps[study] = varcope_file\n",
    "\n",
    "                    # Compute meta-analysis mask as the intersection of all\n",
    "                    # study analysis masks\n",
    "                    if ma_mask is None:\n",
    "                        ma_mask = mask_file\n",
    "                    else:\n",
    "                        cmd = [\n",
    "                            \" fslmaths \\\"\" + mask_file + \"\\\" -min \" +\n",
    "                            \"\\\"\" + ma_mask + \"\\\" \\\"\" + ma_mask_name + \"\\\"\"\n",
    "                            ]\n",
    "                        print \"Running \" + \",\".join(cmd)\n",
    "                        check_call(cmd, shell=True)\n",
    "                        ma_mask = ma_mask_name\n",
    "                else:\n",
    "                    print \"Ignore contrast '\" + str(con_name) + \"'.\"\n",
    "\n",
    "        else:\n",
    "            print \"Query returned no results for study \"+study+\".\"\n",
    "\n",
    "    # Binarize the analysis mask\n",
    "    cmd = [\"fslmaths \\\"\" + ma_mask + \"\\\" -thr 0.9 -bin \\\"\" + ma_mask + \"\\\"\"]\n",
    "    print \"Running \" + \",\".join(cmd)\n",
    "    check_call(cmd, shell=True)\n",
    "\n",
    "    # Sort copes and varcopes by study names\n",
    "    to_merge = {'copes': collections.OrderedDict(sorted(con_maps.items())),\n",
    "                'varcopes': collections.OrderedDict(\n",
    "                    sorted(varcon_maps.items()))}\n",
    "    for file_name, files in to_merge.items():\n",
    "        cmd = [\n",
    "            \"fslmerge -t \\\"\"+os.path.join(out_dir, file_name) +\n",
    "            \".nii.gz\\\" \"+\" \".join(files.values())\n",
    "        ]\n",
    "        print \"Running \" + \",\".join(cmd)\n",
    "        check_call(cmd, shell=True)\n",
    "\n",
    "    # Remove NaNs from copes and varcopes\n",
    "    # (SPM code background with NaNs while FSL uses zeros)\n",
    "    cmd = [\"cd \" + out_dir + \"; fslmaths copes.nii.gz -nan copes\"]\n",
    "    print \"Running \" + \",\".join(cmd)\n",
    "    check_call(cmd, shell=True)\n",
    "\n",
    "    cmd = [\"cd \" + out_dir + \"; fslmaths varcopes.nii.gz -nan varcopes\"]\n",
    "    print \"Running \" + \",\".join(cmd)\n",
    "    check_call(cmd, shell=True)\n",
    "\n",
    "    # Mixed-effects GLM (study-level)\n",
    "    cmd = [\n",
    "        \"cd \" + out_dir + \"; flameo --cope=copes --vc=varcopes --ld=stats \"\n",
    "        \" --dm=\" + os.path.join(FSL_DESIGN_DIR, \"simple_meta_analysis.mat\") +\n",
    "        \" --cs=\" + os.path.join(FSL_DESIGN_DIR, \"simple_meta_analysis.grp\") +\n",
    "        \" --tc=\" + os.path.join(FSL_DESIGN_DIR, \"simple_meta_analysis.con \") +\n",
    "        \" --mask=\\\"\"+ma_mask_name+\"\\\" --runmode=flame1\"]\n",
    "    print \"Running \" + \",\".join(cmd)\n",
    "    check_call(cmd, shell=True)\n",
    "\n",
    "    stat_dir = os.path.join(out_dir, \"stats\")\n",
    "\n",
    "    # FWE Voxel-wise corrected threshold p<0.05 (with a cluster forming\n",
    "    # threshold of p<0.001 uncorrected)\n",
    "    # Scripts from http://blogs.warwick.ac.uk/nichols/entry/flame_without_1st/\n",
    "    cmd = [\n",
    "        \"cd \" + out_dir + \"; \" +\n",
    "        \"echo $($FSLDIR/bin/fslnvols copes) - 1 | bc -l  > stats/dof ;\" +\n",
    "        \"/bin/rm -f stats/zem* stats/zols* stats/mask* ;\" +\n",
    "        \"$FSLDIR/bin/smoothest -d $(cat stats/dof) -m \" + ma_mask_name +\n",
    "        \" -r stats/res4d > stats/smoothness ;\" +\n",
    "        \"awk '/VOLUME/ {print $2}' stats/smoothness > thresh_zstat1.vol ;\" +\n",
    "        \"awk '/DLH/ {print $2}' stats/smoothness > thresh_zstat1.dlh ;\" +\n",
    "        \"$FSLDIR/bin/fslmaths stats/zstat1 -mas \" + ma_mask_name +\n",
    "        \" thresh_zstat1;\" +\n",
    "        \"$FSLDIR/bin/cluster -i thresh_zstat1 -c stats/cope1 -t 3.1 -p 0.05\" +\n",
    "        \" -d $(cat thresh_zstat1.dlh) --volume=$(cat thresh_zstat1.vol) \" +\n",
    "        \"--othresh=thresh_zstat1 -o cluster_mask_zstat1 --connectivity=26 \" +\n",
    "        \"--mm --olmax=lmax_zstat1_tal.txt > cluster_zstat1_std.txt;\" +\n",
    "        \"$FSLDIR/bin/cluster2html . cluster_zstat1 -std;\" +\n",
    "        \"MinMax=$($FSLDIR/bin/fslstats thresh_zstat1 -l 0.0001 -R);\" +\n",
    "        \"$FSLDIR/bin/overlay 1 0 $FSLDIR/data/standard/MNI152_T1_2mm.nii.gz \" +\n",
    "        \"-a thresh_zstat1 $MinMax \" +\n",
    "        \"rendered_thresh_zstat1;\" +\n",
    "        \"$FSLDIR/bin/slicer rendered_thresh_zstat1 -S 2 750 \" +\n",
    "        \"rendered_thresh_zstat1.png;\" +\n",
    "        \"cp $FSLDIR/etc/luts/ramp.gif .ramp.gif\"\n",
    "    ]\n",
    "    print \"Running \" + \",\".join(cmd)\n",
    "    check_call(cmd, shell=True)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
